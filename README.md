# PCA
Principal Component Analysis (PCA) is a multivariate statistical technique using sophisticated underlying mathematical principles to transform a number of possibly correlated variables into a smaller number of variables called principal components. Seeks a space of lower dimensionality, known as the principal subspace.

# PPCA
PPCA using EM algorithm does not require computing the sample covariance and has a complexity limited by O (knp) operations where k is the number of leading eigenvectors to be learned7, in contrast with conventional PCA which has complexity O(n3 ). The EM is an iterative procedure for finding the subspace spanned by the k leading eigenvectors without explicit computation of the sample covariance7.

# Kernel â€“PCA
PCA will always detect all structure in a given data set, because of linearity. By using suitable nonlinear features, we can extract more information. Vapnik Chervonenkis theory tells us that often mappings our data into a higher dimensional space than the dimension of the input space provide us with greater classification power and the data could become more easily separated.
